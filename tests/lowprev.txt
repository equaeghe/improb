Regression tests for the LowPrev class
======================================

Natural extension of a coherent lower prevision
-----------------------------------------------

>>> from improb.lowprev import LowPrev
>>> lpr = LowPrev(3)
>>> print "%.6f" % lpr.get_lower([1,2,3])
1.000000
>>> print "%.6f" % lpr.get_upper([1,2,3])
3.000000
>>> lpr.set_lower([1,2,3], 1.5)
>>> lpr.set_upper([1,2,3], 2.5)
>>> print "%.6f" % lpr.get_lower([1,2,3])
1.500000
>>> print "%.6f" % lpr.get_upper([1,2,3])
2.500000

Frechet bounds
--------------

>>> from improb.lowprev import LowPrev
>>> lpr = LowPrev(4)
>>> lpr.set_precise([1,1,0,0], 0.6)
>>> lpr.set_precise([0,1,1,0], 0.7)
>>> print "%.6f" % lpr.get_lower([0,1,0,0]) # max(0.6+0.7-1,0)
0.300000
>>> print "%.6f" % lpr.get_upper([0,1,0,0]) # min(0.6,0.7)
0.600000
>>> lpr.is_linear()
True

Avoiding sure loss
------------------

This example incurs sure loss because the maximum of the sum of the gambles
[1,2,3,0] and [3,2,1,0] is 4, however 2.5 + 2.5 is strictly larger than 4.

>>> from improb.lowprev import LowPrev
>>> lpr = LowPrev(4)
>>> lpr.set_lower([1,2,3,0], 2.5)
>>> lpr.is_avoiding_sure_loss()
True
>>> lpr.set_lower([3,2,1,0], 2.5)
>>> lpr.is_avoiding_sure_loss()
False
>>> lpr_s_t = LowPrev(9)
>>> lpr_s_t.set_lower([1,0,0,0,0,0,0,0,0], 0.500)
>>> lpr_s_t.set_upper([1,0,0,0,0,0,0,0,0], 0.666)
>>> lpr_s_t.set_lower([0,1,0,0,0,0,0,0,0], 0.222)
>>> lpr_s_t.set_upper([0,1,0,0,0,0,0,0,0], 0.272)
>>> lpr_s_t.set_lower([0,0,1,0,0,0,0,0,0], 0.125)
>>> lpr_s_t.set_upper([0,0,1,0,0,0,0,0,0], 0.181)
>>> lpr_s_t.set_lower([0,0,0,1,0,0,0,0,0], 0.222)
>>> lpr_s_t.set_upper([0,0,0,1,0,0,0,0,0], 0.333)
>>> lpr_s_t.set_lower([0,0,0,0,1,0,0,0,0], 0.363)
>>> lpr_s_t.set_upper([0,0,0,0,1,0,0,0,0], 0.444)
>>> lpr_s_t.set_lower([0,0,0,0,0,1,0,0,0], 0.250)
>>> lpr_s_t.set_upper([0,0,0,0,0,1,0,0,0], 0.363)
>>> lpr_s_t.set_lower([0,0,0,0,0,0,1,0,0], 0.111)
>>> lpr_s_t.set_upper([0,0,0,0,0,0,1,0,0], 0.166)
>>> lpr_s_t.set_lower([0,0,0,0,0,0,0,1,0], 0.333)
>>> lpr_s_t.set_upper([0,0,0,0,0,0,0,1,0], 0.363)
>>> lpr_s_t.set_lower([0,0,0,0,0,0,0,0,1], 0.454)
>>> lpr_s_t.set_upper([0,0,0,0,0,0,0,0,1], 0.625)
>>> lpr_s_t.is_avoiding_sure_loss()
False

Coherence
---------

>>> from improb.lowprev import LowPrev
>>> lpr = LowPrev(4)
>>> lpr.set_lower([1,2,3,0], 2.5)
>>> lpr.is_coherent()
True
>>> lpr.set_upper([2,4,6,0], 3) # coherence requires at least 5
>>> lpr.is_coherent()
False

Linearity
---------

>>> from improb.lowprev import LowPrev
>>> lpr = LowPrev(4)
>>> lpr.set_lower([1,2,3,0], 2.5)
>>> lpr.is_linear()
False
>>> lpr.set_upper([2,4,6,0], 5)
>>> lpr.is_linear()
True

Marginal Extension
------------------

Finding coherent lower and upper bounds for the oil catter example in

Kikuti, D., Cozman, F., de Campos, C.: Partially ordered preferences
in decision trees: Computing strategies with imprecision in
probabilities. In: R. Brafman, U. Junker (eds.) IJCAI-05
Multidisciplinary Workshop on Advances in Preference Handling,
pp. 118â€“123 (2005)

>>> from improb.lowprev import LowPrev
>>> # lower previsions over s, given t
>>> lpr_s_t = [LowPrev(3), LowPrev(3), LowPrev(3)]
>>> # lower prevision over t
>>> lpr_t = LowPrev(3)
>>> lpr_s_t[0].set_lower([1,0,0], 0.5)
>>> lpr_s_t[0].set_upper([1,0,0], 0.666)
>>> lpr_s_t[0].set_lower([0,1,0], 0.222)
>>> lpr_s_t[0].set_upper([0,1,0], 0.272)
>>> lpr_s_t[0].set_lower([0,0,1], 0.125)
>>> lpr_s_t[0].set_upper([0,0,1], 0.181)
>>> lpr_s_t[0].is_coherent()
False
>>> print(lpr_s_t[0].get_lower([1,0,0])) # not coherent!
0.547
>>> print(lpr_s_t[0].get_upper([1,0,0])) # not coherent!
0.653
>>> print(lpr_s_t[0].get_lower([0,1,0]))
0.222
>>> print(lpr_s_t[0].get_upper([0,1,0]))
0.272
>>> print(lpr_s_t[0].get_lower([0,0,1]))
0.125
>>> print(lpr_s_t[0].get_upper([0,0,1]))
0.181
>>> lpr_s_t[1] = LowPrev(3)
>>> lpr_s_t[1].set_lower([1,0,0], 0.222)
>>> lpr_s_t[1].set_upper([1,0,0], 0.333)
>>> lpr_s_t[1].set_lower([0,1,0], 0.363)
>>> lpr_s_t[1].set_upper([0,1,0], 0.444)
>>> lpr_s_t[1].set_lower([0,0,1], 0.250)
>>> lpr_s_t[1].set_upper([0,0,1], 0.363)
>>> lpr_s_t[1].is_coherent()
True
>>> print(lpr_s_t[1].get_lower([1,0,0]))
0.222
>>> print(lpr_s_t[1].get_upper([1,0,0]))
0.333
>>> print(lpr_s_t[1].get_lower([0,1,0]))
0.363
>>> print(lpr_s_t[1].get_upper([0,1,0]))
0.444
>>> print(lpr_s_t[1].get_lower([0,0,1]))
0.25
>>> print(lpr_s_t[1].get_upper([0,0,1]))
0.363
>>> lpr_s_t[2] = LowPrev(3)
>>> lpr_s_t[2].set_lower([1,0,0], 0.111)
>>> lpr_s_t[2].set_upper([1,0,0], 0.166)
>>> lpr_s_t[2].set_lower([0,1,0], 0.333)
>>> lpr_s_t[2].set_upper([0,1,0], 0.363)
>>> lpr_s_t[2].set_lower([0,0,1], 0.454)
>>> lpr_s_t[2].set_upper([0,0,1], 0.625)
>>> lpr_s_t[2].is_coherent()
False
>>> print(lpr_s_t[2].get_lower([1,0,0]))
0.111
>>> print(lpr_s_t[2].get_upper([1,0,0]))
0.166
>>> print(lpr_s_t[2].get_lower([0,1,0]))
0.333
>>> print(lpr_s_t[2].get_upper([0,1,0]))
0.363
>>> print(lpr_s_t[2].get_lower([0,0,1])) # not coherent!
0.471
>>> print(lpr_s_t[2].get_upper([0,0,1])) # not coherent!
0.556
>>> lpr_t.set_lower([1,0,0], 0.181)
>>> lpr_t.set_upper([1,0,0], 0.222)
>>> lpr_t.set_lower([0,1,0], 0.333)
>>> lpr_t.set_upper([0,1,0], 0.363)
>>> lpr_t.set_lower([0,0,1], 0.444)
>>> lpr_t.set_upper([0,0,1], 0.454)
>>> lpr_t.is_coherent()
False
>>> print(lpr_t.get_lower([1,0,0])) # not coherent!
0.183
>>> print(lpr_t.get_upper([1,0,0]))
0.222
>>> print(lpr_t.get_lower([0,1,0]))
0.333
>>> print(lpr_t.get_upper([0,1,0]))
0.363
>>> print(lpr_t.get_lower([0,0,1]))
0.444
>>> print(lpr_t.get_upper([0,0,1]))
0.454
>>> # a gamble which is a function of s and t; t comes as first
>>> # argument (in order to match lpr_s_t): gamble_s_t[t][s]
>>> gamble_s_t = [[-7,5,20], [-7,5,20], [-7,5,20]]
>>> # calculate its lower prevision by marginal extension
>>> print(lpr_t.get_lower([lpr_s.get_lower(gamble_s)
...                        for lpr_s, gamble_s in zip(lpr_s_t, gamble_s_t)]))
5.846906
>>> print(lpr_t.get_upper([lpr_s.get_upper(gamble_s)
...                        for lpr_s, gamble_s in zip(lpr_s_t, gamble_s_t)]))
8.486768
>>> # another gamble which is a function of s and t
>>> gamble_s_t = [[-1,-1,-1], [-1,11,26], [-1,11,26]]
>>> # calculate its lower prevision by marginal extension
>>> print(lpr_t.get_lower([lpr_s.get_lower(gamble_s)
...                        for lpr_s, gamble_s in zip(lpr_s_t, gamble_s_t)]))
10.506248
>>> print(lpr_t.get_upper([lpr_s.get_upper(gamble_s)
...                        for lpr_s, gamble_s in zip(lpr_s_t, gamble_s_t)]))
12.995135

Maximality
----------

Example taken from:

Matthias C. M. Troffaes. Decision making under uncertainty using
imprecise probabilities. International Journal of Approximate
Reasoning, 45(1):17-29, May 2007.

>>> from improb.lowprev import LowPrev
>>> from improb.decision import filter_maximal
>>> lpr = LowPrev(2)
>>> lpr.set_lower([1, 0], 0.28)
>>> lpr.set_upper([1, 0], 0.70)
>>> list(filter_maximal([[4, 0], [0, 4], [3, 2], [0.5, 3], [2.35, 2.35], [4.1, -0.3]], lpr.dominates)) == [[4, 0], [0, 4], [3, 2], [2.35, 2.35]]
True
